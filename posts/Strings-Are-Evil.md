<p>Reducing memory allocations from 7.5GB to&#xA0;32KB</p><h3>Contents</h3><ul><li><a href="https://medium.com/p/a803d05e5ce3#abe8">Context of the&#xA0;problem</a></li><li><a href="https://medium.com/p/a803d05e5ce3#6415">Establishing a&#xA0;baseline</a></li><li><a href="https://medium.com/p/a803d05e5ce3#88ac">Easy win&#xA0;1</a></li><li><a href="https://medium.com/p/a803d05e5ce3#28db">Easy win&#xA0;2</a></li><li><a href="https://medium.com/p/a803d05e5ce3#7f99">Splits are never&#xA0;cool</a></li><li><a href="https://medium.com/p/a803d05e5ce3#cc7d">Lists are not always&#xA0;nice</a></li><li><a href="https://medium.com/p/a803d05e5ce3#b736">Pooling byte&#xA0;arrays</a></li><li><a href="https://medium.com/p/a803d05e5ce3#3620">Goodbye StringBuilder</a></li><li><a href="https://medium.com/p/a803d05e5ce3#1cc7">Skipping commas</a></li><li><a href="https://medium.com/p/a803d05e5ce3#4511">The war between classes and&#xA0;structs</a></li><li><a href="https://medium.com/p/a803d05e5ce3#0b6c">Goodbye StreamReader</a></li><li><a href="https://medium.com/p/a803d05e5ce3#da2c">TLDR&#x200A;&#x2014;&#x200A;Give me a&#xA0;table</a></li></ul><h3>Context of the&#xA0;problem</h3><p><a href="https://codeweavers.net/">Codeweavers</a> is a financial services software company, part of what we do is to enable our customers to bulk import their data into our platform. For our services we require up-to-date information from all our clients, which includes lenders and manufacturers across the UK. Each of those imports can contain several hundred megabytes uncompressed data, which will often be imported on a daily&#xA0;basis.</p><p>This data is then used to power our real-time calculations. Currently this import process has to take place outside of business hours because of the impact it has on memory&#xA0;usage.</p><p>In this article we will explore potential optimisations to the import process specifically within the context of reducing memory during the import process. If you want to have a go yourself, you can use <a href="https://gist.github.com/indy-singh/f10b76c4a00e807625f9b5a8d1989772">this code</a> to generate a sample input file and you can find all of the code talked about&#xA0;<a href="https://github.com/indy-singh/StringsAreEvil">here</a>.</p><h3>Establishing a&#xA0;baseline</h3><p>The current implementation uses StreamReader and passes each line to the lineParser.</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9e6d1b9676d1508fada0eed416cf5d04/href">https://medium.com/media/9e6d1b9676d1508fada0eed416cf5d04/href</a></iframe><p>The most naive implementation of a line parser that we originally had looked something like&#xA0;this:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/7efd374838b638e413fef1a61815da58/href">https://medium.com/media/7efd374838b638e413fef1a61815da58/href</a></iframe><p>The ValueHolder class is used later on in the import process to insert information into the database:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/afcb770d65486f2cdff212f82f202126/href">https://medium.com/media/afcb770d65486f2cdff212f82f202126/href</a></iframe><p>Running this example as a command line application and enabling monitoring:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b18f5d9ef4c9b008ba847df8f1522b37/href">https://medium.com/media/b18f5d9ef4c9b008ba847df8f1522b37/href</a></iframe><p>Our main goal today is to reduce <a href="https://blog.maartenballiauw.be/post/2016/10/19/making-net-code-less-allocatey-garbage-collector.html">allocated</a> <a href="http://tooslowexception.com/allocation-is-cheap-until-it-is-not/">memory</a>. In short, the less memory we allocate, the less work the garbage collector has to do. There are <a href="https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals#generations">three generations</a> that garbage collector operates against, we will also be monitoring those. Garbage collection is a complex topic and outside of the scope of this article; but a good rule of thumb is that short-lived objects should never be promoted past generation 0.</p><p>We can see V01 has the following statistics:-</p><pre><code class="language-markup">Took: 8,750 msAllocated: 7,412,303 kbPeak Working Set: 16,720 kbGen 0 collections: 1809Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Almost 7.5 GB of memory allocations to parse a three hundred megabyte file is less than ideal. Now that we have established the baseline, let us find some easy&#xA0;wins&#x2026;</p><h3>Easy win&#xA0;1</h3><p>Eagle-eyed readers will have spotted that we string.Split(&apos;,&apos;) twice; once in the line parser and again in the constructor of ValueHolder. This is wasteful, we can overload the constructor of ValueHolder to accept a string[] array and split the line once in the parser. After that simple change the statistics for V02 are&#xA0;now:-</p><pre><code class="language-markup">Took: 6,922 msAllocated: 4,288,289 kbPeak Working Set: 16,716 kbGen 0 collections: 1046Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Great! We are down from 7.5GB to 4.2GB. But that is still a lot of memory allocations for processing a three hundred megabyte&#xA0;file.</p><h3>Easy win&#xA0;2</h3><p>Quick analysis of the input file reveals that there are 10,047,435 lines, we are only interested in lines that are prefixed with MNO of which there are 10,036,466 lines. That means we are unnecessarily processing an additional 10,969 lines. A quick change to V03 to only parse lines prefixed with&#xA0;MNO:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/a8b5adb1b6348a4a8e06f75819431027/href">https://medium.com/media/a8b5adb1b6348a4a8e06f75819431027/href</a></iframe><p>This means we defer splitting the entire line until we know it is a line we are interested in. Unfortunately this did not save us much memory. Mainly because we are interested in 99.89% of the lines in the file. The statistics for&#xA0;V03:-</p><pre><code class="language-markup">Took: 8,375 msAllocated: 4,284,873 kbPeak Working Set: 16,744 kbGen 0 collections: 1046Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>It is time to break out the trusty profiler, in this case <a href="https://www.jetbrains.com/profiler/">dotTrace</a>:-</p><figure><img alt src="https://hackernoon.com/hn-images/1*k2frDbNstVrxqnWeBCAG-A.jpeg"></figure><p>Strings in the&#xA0;.NET ecosystem are immutable. Meaning that anything we do to a string <em>always</em> returns a brand new copy. Therefore calling string.Split(&apos;,&apos;) on every line (remember there are 10,036,466 lines we are interested in) returns that line split into several smaller strings. Each line at minimum has five sections we want to process. That means in the lifetime of the import process we create at least 50,182,330 strings..! Next we will explore what we can do to eliminate the use of string.Split(&apos;,&apos;).</p><h3>Splits are never&#xA0;cool</h3><p>A typical line we are interested in looks something like&#xA0;this:-</p><pre><code class="language-markup">MNO,3,813496,36,30000,78.19,,</code></pre><p>Calling string.Split(&apos;,&apos;) on the above line will return a string[] containing:-</p><pre><code class="language-markup">&apos;MNO&apos;&apos;3&apos;&apos;813496&apos;&apos;36&apos;&apos;30000&apos;&apos;78.19&apos;&apos;&apos;&apos;&apos;</code></pre><p>Now at this point we can make some guarantees about the file we are importing:-</p><ul><li>The length of each line is not&#xA0;fixed</li><li>The number of sections that are delimited by a comma are&#xA0;fixed</li><li>We only use the first three characters of each line to determine our interest in the&#xA0;line</li><li>This means there are five sections we are interested in but the section length is&#xA0;unknown</li><li>Sections do not change locations (e.g MNO is always the first&#xA0;section)</li></ul><p>Guarantees established, we can now build a short lived index of the positions of all the commas for a given&#xA0;line:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0aecfff5995cd2eb17c6aa7c675096d7/href">https://medium.com/media/0aecfff5995cd2eb17c6aa7c675096d7/href</a></iframe><p>Once we know the position of each comma, we can directly access the section we care about and manually parse that&#xA0;section.</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8f55a2295ff28a6bed29cb9e23cd5773/href">https://medium.com/media/8f55a2295ff28a6bed29cb9e23cd5773/href</a></iframe><p>Putting it all together:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f30a9957615f738c0e88487e3afe6e74/href">https://medium.com/media/f30a9957615f738c0e88487e3afe6e74/href</a></iframe><p>Running V04 reveals this statistics:-</p><pre><code class="language-markup">Took: 9,813 msAllocated: 6,727,664 kbPeak Working Set: 16,872 kbGen 0 collections: 1642Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Whoops, that is worse than expected. It is an easy mistake to make but dotTrace can help us&#xA0;here&#x2026;</p><figure><img alt src="https://hackernoon.com/hn-images/1*-lFgd7zrdkjp3COO40mLBg.jpeg"></figure><p>Constructing a StringBuilder for every section in every line is incredibly expensive. Luckily it is a quick fix, we constructor a single StringBuilder on the construction of V05 and clear it before each usage. V05 now has the following statistics:-</p><pre><code class="language-markup">Took: 9,125 msAllocated: 3,199,195 kbPeak Working Set: 16,636 kbGen 0 collections: 781Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Phew we are back on the downwards trends. We started at 7.5GB and now we are down to&#xA0;3.2GB.</p><h3>Lists are not always&#xA0;nice</h3><p>At this point dotTrace becomes an essential part of the optimisation process. Looking at V05 dotTrace&#xA0;output:-</p><figure><img alt src="https://hackernoon.com/hn-images/1*UEqCJXD2xuE4Euokoc8flg.jpeg"></figure><p>Building the short lived index of commas positions is expensive. As underneath any List&lt;T&gt; is just a standard T[] array. The framework takes care of re-sizing the underlying array when elements are added. This is useful and very handy in typical scenarios. However, we know that there are six sections we need to process (but we are only interested in five of those sections), ergo there are at least seven commas we want indexes for. We can optimise for&#xA0;that:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b40fecfcde0bcb437c158c3e141fcf86/href">https://medium.com/media/b40fecfcde0bcb437c158c3e141fcf86/href</a></iframe><p>V06 statistics:-</p><pre><code class="language-markup">Took: 8,047 msAllocated: 2,650,318 kbPeak Working Set: 16,560 kbGen 0 collections: 647Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>2.6GB is pretty good, but what happens if we force the compiler to use byte for this method instead of the compiler defaulting to use&#xA0;int:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c2f9b937862d6531f3ed8701844beb95/href">https://medium.com/media/c2f9b937862d6531f3ed8701844beb95/href</a></iframe><p>Re-running V06:-</p><pre><code class="language-markup">Took: 8,078 msAllocated: 2,454,297 kbPeak Working Set: 16,548 kbGen 0 collections: 599Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>2.6GB was pretty good, 2.4GB is even better. This is because an int has a much <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/integral-types-table">larger range</a> than a&#xA0;byte.</p><h3>Pooling byte&#xA0;arrays</h3><p>V06 now has a byte[] array that holds the index of each comma for each line. It is a short lived array, but it is created many times. We can eliminate the cost of creating a new byte[] for each line by using a recent addition to the&#xA0;.NET ecosystem; Systems.Buffers. Adam Sitnik has a <a href="http://adamsitnik.com/Array-Pool/">great breakdown</a> on using it and why you should. The important thing to remember when using ArrayPool&lt;T&gt;.Shared is you must <em>always</em> return the rented buffer after you are done using it otherwise you <strong>will</strong> introduce a memory leak into your application.</p><p>This is what V07 looks&#xA0;like:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/351c630ba9f6052517a870d21e059baf/href">https://medium.com/media/351c630ba9f6052517a870d21e059baf/href</a></iframe><p>And V07 has the following statistics:-</p><pre><code class="language-markup">Took: 8,891 msAllocated: 2,258,272 kbPeak Working Set: 16,752 kbGen 0 collections: 551Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Down to 2.2GB, having started at 7.5GB. It is pretty good, but we are not done&#xA0;yet.</p><h3>Goodbye StringBuilder</h3><p>Profiling V07 reveals the next problem:-</p><figure><img alt src="https://hackernoon.com/hn-images/1*fJErhIAtFGBDq7NuUYWfkQ.jpeg"></figure><p>Calling StringBuilder.ToString() inside of the decimal and int parsers is incredibly expensive. It is time to deprecate StringBuilder and write our own&#xB9; int and decimal parsers without relying on strings and calling int.parse() / decimal.parse(). According to the profiler this should shave off around 1GB. After writing our own int and decimal parsers V08 now clocks in&#xA0;at:-</p><pre><code class="language-markup">Took: 6,047 msAllocated: 1,160,856 kbPeak Working Set: 16,816 kbGen 0 collections: 283Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>1.1GB is a huge improvement from where we were last (2.2GB) and even better than the baseline&#xA0;(7.5GB).</p><p>&#xB9; Code can be found&#xA0;<a href="https://github.com/indy-singh/StringsAreEvil/blob/master/StringsAreEvil/LineParserV08.cs">here</a></p><h3>Skipping commas</h3><p>Until V08 our strategy has been to find the index of every comma on each line and then use that information to create a sub-string which is then parsed by calling int.parse() / decimal.parse(). V08 deprecates the use of sub-strings but still uses the short lived index of comma positions.</p><p>An alternative strategy would be to skip to the section we are interested in by counting the number of preceding commas then parse anything after the required number of commas and return when we hit the next&#xA0;comma.</p><p>We have previously guaranteed that:-</p><ul><li>Each section is preceded by a&#xA0;comma.</li><li>And that the location of each section within a line does not&#xA0;change.</li></ul><p>This would also means we can deprecate the rented byte[] array because we are no longer building a short lived&#xA0;index:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/ca545e99215aa810eb48de7d61bd8880/href">https://medium.com/media/ca545e99215aa810eb48de7d61bd8880/href</a></iframe><p>Unfortunately V09 does not save us any memory, it does however reduce the time&#xA0;taken:-</p><pre><code class="language-markup">Took: 5,703 msAllocated: 1,160,856 kbPeak Working Set: 16,572 kbGen 0 collections: 283Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Another benefit of V09 is that it reads much more closer to the original implementation.</p><h3>The war between classes and&#xA0;structs</h3><p>This blog post is not going to cover the difference or the pros/cons of classes vs structs. That topic has been <a href="https://softwareengineering.stackexchange.com/questions/92339/when-do-you-use-a-struct-instead-of-a-class">covered</a> <a href="https://stackoverflow.com/questions/13049/whats-the-difference-between-struct-and-class-in-net">many</a> <a href="https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/choosing-between-class-and-struct">times</a>. In this particular context, it is beneficial to use a struct. Changing ValueHolder to a struct in V10 has the following statistics:-</p><pre><code class="language-markup">Took: 5,594 msAllocated: 768,803 kbPeak Working Set: 16,512 kbGen 0 collections: 187Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Finally, we are below the 1GB barrier. Also, word of warning please do not use a struct blindly, always test your code and make sure the use case is&#xA0;correct.</p><h3>Goodbye StreamReader</h3><p>As of V10 the line parser itself is virtually allocation free. dotTrace reveals where the remaining allocations occur:-</p><figure><img alt src="https://hackernoon.com/hn-images/1*yV3Q1VN-VFwFVNgBwFMqew.jpeg"></figure><p>Well this is awkward, the framework is costing us memory allocations. We can interact with the file at a lower-level than a StreamReader:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/7c7ef9b0bb85fc189f46247b705165ff/href">https://medium.com/media/7c7ef9b0bb85fc189f46247b705165ff/href</a></iframe><p>V11 statistics:-</p><pre><code class="language-markup">Took: 5,594 msAllocated: 695,545 kbPeak Working Set: 16,452 kbGen 0 collections: 169Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Well, 695MB is still better than 768MB. Okay, that was not the improvement I was expecting (and rather anti-climatic). Until, we remember we have previously seen and solved this problem before. In V07 we used ArrayPool&lt;T&gt;.Shared to prevent lots of small byte[]. We can do the same&#xA0;here:-</p><iframe src width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0778f743114d116c4db278c2918ffca0/href">https://medium.com/media/0778f743114d116c4db278c2918ffca0/href</a></iframe><p>The final version of V11 has the following statistics:-</p><pre><code class="language-markup">Took: 6,781 msAllocated: 32 kbPeak Working Set: 12,620 kbGen 0 collections: 0Gen 1 collections: 0Gen 2 collections: 0</code></pre><p>Yes, only 32kb of memory allocations. That <strong><em>is</em></strong> the climax I was looking&#xA0;for.</p><h3>TLDR&#x200A;&#x2014;&#x200A;Give me a&#xA0;table</h3><iframe src="https://cdn.embedly.com/widgets/media.html?url=https%3A%2F%2Fdatawrapper.dwcdn.net%2FlXNKV%2F2%2F&amp;src=%2F%2Fdatawrapper.dwcdn.net%2FlXNKV%2F2%2F&amp;type=text%2Fhtml&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;schema=dwcdn" width="600" height="521" frameborder="0" scrolling="no"><a href="https://medium.com/media/1ed6a5446d0c70436aaf813054c6ec15/href">https://medium.com/media/1ed6a5446d0c70436aaf813054c6ec15/href</a></iframe><figure><a href="https://goo.gl/w4Pbea"><img alt src="https://hackernoon.com/hn-images/1*PZjwR1Nbluff5IMI6Y1T6g@2x.png"></a></figure>                <div class="archive-tags">                                        <a class="tag" href="https://hackernoon.com/tagged/software-development">Software Development</a>                                        <a class="tag" href="https://hackernoon.com/tagged/optimization">Optimization</a>                                        <a class="tag" href="https://hackernoon.com/tagged/csharp">Csharp</a>                                        <a class="tag" href="https://hackernoon.com/tagged/programming">Programming</a>                                        <a class="tag" href="https://hackernoon.com/tagged/coding">Coding</a>                  </div>                <div class="twitter-discussion">          <a target="_blank" href="https://twitter.com/search?q=https%3A%2F%2Fhackernoon.com%2Fstrings-are-evil-a803d05e5ce3">Continue the discussion <i class="fab fa-twitter"></i></a>        </div>